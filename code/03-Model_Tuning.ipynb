{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from text_helper import word_splitter, sentence_count, stop_word_counter, punc_counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "\n",
    "rs = 91923 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data_final.csv')\n",
    "\n",
    "df['response_cleaned'] = df['response'].apply(lambda x: re.sub('[\\\\n]{2,}', '\\n', x))\n",
    "df['response_cleaned'] = df['response_cleaned'].apply(lambda x: re.sub(r\"\\/*u\\/[\\S]+\", 'they', x))\n",
    "\n",
    "df['num_words'] = df['response_cleaned'].apply(lambda x: word_splitter(x)[0])\n",
    "df['stop_words'] = df['response_cleaned'].apply(stop_word_counter)\n",
    "df['num_sentences'] = df['response_cleaned'].apply(lambda x: sentence_count(x)[0]) \n",
    "df['sentence_length'] = df['response_cleaned'].apply(lambda x: sentence_count(x)[1])\n",
    "df['word_length'] = df['response_cleaned'].apply(lambda x: word_splitter(x)[1])\n",
    "\n",
    "punc_count = df['response_cleaned'].apply(punc_counter)\n",
    "df['punc_ratio'] = punc_count / df['num_words']\n",
    "\n",
    "X = df[['subreddit', 'response_cleaned', 'num_words', 'stop_words', 'num_sentences', 'sentence_length', 'word_length', 'punc_ratio']]\n",
    "y = df['fake']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = rs, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET Train: 1.0\n",
      "ET Test: 0.9043221278167713\n",
      "----\n",
      "RSVC Train: 0.9125508067495997\n",
      "RSVC Test: 0.8880679719246398\n",
      "----\n",
      "AdaBoost Train: 0.8949378002217022\n",
      "AdaBoost Test: 0.888806797192464\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Recreating out pipelines and our pre-tuning baselines for our three models\n",
    "meta_pipe = Pipeline(\n",
    "    [\n",
    "        ('ss', StandardScaler()) # Since we're done testing with Naive Bayes we can use the default parameters here\n",
    "    ]\n",
    ")\n",
    "\n",
    "text_pipe = Pipeline(\n",
    "    [\n",
    "        ('vect', CountVectorizer())\n",
    "    ]\n",
    ")\n",
    "\n",
    "subreddit_pipe = Pipeline(\n",
    "    [\n",
    "        ('ohe', OneHotEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "col_trans = ColumnTransformer(\n",
    "    [\n",
    "        ('meta', meta_pipe, make_column_selector(dtype_include = np.number)),\n",
    "        ('text', text_pipe, 'response_cleaned'),\n",
    "        ('ohe', subreddit_pipe, ['subreddit'])\n",
    "    ],\n",
    "    n_jobs = 6\n",
    ")\n",
    "\n",
    "\n",
    "et_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('et', ExtraTreesClassifier(random_state = rs, n_jobs = 6))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rsvc_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('rsvc', SVC(kernel = 'rbf'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "adbc_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('adbc', AdaBoostClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "et_pipe.fit(X_train, y_train)\n",
    "rsvc_pipe.fit(X_train, y_train)\n",
    "adbc_pipe.fit(X_train, y_train)\n",
    "\n",
    "print(\"ET Train: {}\\nET Test: {}\\n----\".format(et_pipe.score(X_train, y_train), et_pipe.score(X_test, y_test)))\n",
    "print(\"RSVC Train: {}\\nRSVC Test: {}\\n----\".format(rsvc_pipe.score(X_train, y_train), rsvc_pipe.score(X_test, y_test)))\n",
    "print(\"AdaBoost Train: {}\\nAdaBoost Test: {}\\n----\".format(adbc_pipe.score(X_train, y_train), adbc_pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining our text_pipe from before to include a standard scaler\n",
    "text_pipe = Pipeline(\n",
    "    [\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('ss', StandardScaler(with_mean = False)) # scaling with mean doesn't work on sparse arrays so we'll have to do without\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET Train: 1.0\n",
      "ET Test: 0.9009974141115626\n",
      "----\n",
      "RSVC Train: 0.9338588496120211\n",
      "RSVC Test: 0.902844477281123\n",
      "----\n",
      "AdaBoost Train: 0.9022047050129326\n",
      "AdaBoost Test: 0.8766161802733653\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "vect_params = {\n",
    "    'ct__text__vect' : [TfidfVectorizer()]\n",
    "}\n",
    "\n",
    "et_grid = GridSearchCV(\n",
    "    et_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 2,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "rsvc_grid = GridSearchCV(\n",
    "    rsvc_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 2,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "adb_grid = GridSearchCV(\n",
    "    adbc_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 2,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "print(\"ET Train: {}\\nET Test: {}\\n----\".format(et_grid.score(X_train, y_train), et_grid.score(X_test, y_test)))\n",
    "print(\"RSVC Train: {}\\nRSVC Test: {}\\n----\".format(rsvc_grid.score(X_train, y_train), rsvc_grid.score(X_test, y_test)))\n",
    "print(\"AdaBoost Train: {}\\nAdaBoost Test: {}\\n----\".format(adb_grid.score(X_train, y_train), adb_grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer()\n",
      "TfidfVectorizer()\n",
      "CountVectorizer()\n"
     ]
    }
   ],
   "source": [
    "print(et_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(rsvc_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(adb_grid.best_estimator_['ct'].transformers[1][1]['vect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our tree-based models prefer a count vectorizer but our support vector classifier performs better with the TF-IDF vectorizer. However, we see a sharp performance drop off for the support vector model now that our data is scaled which is disconcerting. Our actual performance for the other two models is identical with or without scaling so let's not scale since it doesn't give us anything it seems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pipe = Pipeline(\n",
    "    [\n",
    "        ('ss', StandardScaler()) # No need to worry about negative values anymore\n",
    "    ]\n",
    ")\n",
    "\n",
    "text_pipe = Pipeline(\n",
    "    [\n",
    "        ('vect', CountVectorizer()) # Removing scaling\n",
    "    ]\n",
    ")\n",
    "\n",
    "subreddit_pipe = Pipeline(\n",
    "    [\n",
    "        ('ohe', OneHotEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "col_trans = ColumnTransformer(\n",
    "    [\n",
    "        ('meta', meta_pipe, make_column_selector(dtype_include = np.number)),\n",
    "        ('text', text_pipe, 'response_cleaned'),\n",
    "        ('ohe', subreddit_pipe, ['subreddit'])\n",
    "    ],\n",
    "    n_jobs = 6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_params = {\n",
    "    'ct__text__vect' : [TfidfVectorizer(), CountVectorizer()]\n",
    "}\n",
    "\n",
    "et_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('et', ExtraTreesClassifier(random_state = rs))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rsvc_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('rsvc', SVC(kernel = 'rbf'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "adbc_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('adbc', AdaBoostClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "et_grid = GridSearchCV(\n",
    "    et_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "rsvc_grid = GridSearchCV(\n",
    "    rsvc_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "adb_grid = GridSearchCV(\n",
    "    adbc_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "print(et_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(\"ET Train: {}\\nET Test: {}\\n----\".format(et_grid.score(X_train, y_train), et_grid.score(X_test, y_test)))\n",
    "print(rsvc_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(\"RSVC Train: {}\\nRSVC Test: {}\\n----\".format(rsvc_grid.score(X_train, y_train), rsvc_grid.score(X_test, y_test)))\n",
    "print(adb_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(\"AdaBoost Train: {}\\nAdaBoost Test: {}\\n----\".format(adb_grid.score(X_train, y_train), adb_grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET Train: 1.0\n",
      "ET Test: 0.9128186183967492\n",
      "----\n",
      "RSVC Train: 0.9100874491932504\n",
      "RSVC Test: 0.8862209087550794\n",
      "----\n",
      "AdaBoost Train: 0.8949378002217022\n",
      "AdaBoost Test: 0.888806797192464\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "vect_params = {\n",
    "    'ct__text__vect__ngram_range' : ((1,1), (1,2), (1,3)),\n",
    "    'ct__text__vect__stop_words' : (None, 'english', stopwords.words('english'))\n",
    "}\n",
    "\n",
    "et_grid = GridSearchCV(\n",
    "    et_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "rsvc_grid = GridSearchCV(\n",
    "    rsvc_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "adb_grid = GridSearchCV(\n",
    "    adbc_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "print(\"ET Train: {}\\nET Test: {}\\n----\".format(et_grid.score(X_train, y_train), et_grid.score(X_test, y_test)))\n",
    "print(\"RSVC Train: {}\\nRSVC Test: {}\\n----\".format(rsvc_grid.score(X_train, y_train), rsvc_grid.score(X_test, y_test)))\n",
    "print(\"AdaBoost Train: {}\\nAdaBoost Test: {}\\n----\".format(adb_grid.score(X_train, y_train), adb_grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(ngram_range=(1, 2))\n",
      "CountVectorizer()\n",
      "CountVectorizer()\n"
     ]
    }
   ],
   "source": [
    "print(et_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(rsvc_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(adb_grid.best_estimator_['ct'].transformers[1][1]['vect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, only our Extra Trees models prefers the non-default parameters. Both Radial SVC and Adaptive Boosting prefer no stop words excluded and no ngrams (single sets of words instead of pairs). Extra Trees prefers bigrams included but otherwise still prefers not removing stop words. This is to be expected since we saw a large difference in stop word usage for real comments vs AI generated ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET Train: 1.0\n",
      "ET Test: 0.9179903952715183\n",
      "----\n",
      "RSVC Train: 0.9061460771030915\n",
      "RSVC Test: 0.8899150350942002\n",
      "----\n",
      "AdaBoost Train: 0.8949378002217022\n",
      "AdaBoost Test: 0.888806797192464\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "vect_params = {\n",
    "    'ct__text__vect__max_features' : (None, 1000, 2000, 4000, 5000)\n",
    "}\n",
    "\n",
    "et_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('et', ExtraTreesClassifier(random_state = rs))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rsvc_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('rsvc', SVC(kernel = 'rbf'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "adbc_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('adbc', AdaBoostClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "et_grid = GridSearchCV(\n",
    "    et_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "rsvc_grid = GridSearchCV(\n",
    "    rsvc_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "adb_grid = GridSearchCV(\n",
    "    adbc_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "print(\"ET Train: {}\\nET Test: {}\\n----\".format(et_grid.score(X_train, y_train), et_grid.score(X_test, y_test)))\n",
    "print(\"RSVC Train: {}\\nRSVC Test: {}\\n----\".format(rsvc_grid.score(X_train, y_train), rsvc_grid.score(X_test, y_test)))\n",
    "print(\"AdaBoost Train: {}\\nAdaBoost Test: {}\\n----\".format(adb_grid.score(X_train, y_train), adb_grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(max_features=2000)\n",
      "CountVectorizer(max_features=2000)\n",
      "CountVectorizer(max_features=1000)\n"
     ]
    }
   ],
   "source": [
    "print(et_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(rsvc_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(adb_grid.best_estimator_['ct'].transformers[1][1]['vect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to narrow this down a bit further, maybe they'll end up wanting the same number of max features once we've gotten more specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET Train: 1.0\n",
      "ET Test: 0.9157739194680458\n",
      "----\n",
      "RSVC Train: 0.9038058874245597\n",
      "RSVC Test: 0.8902844477281123\n",
      "----\n",
      "AdaBoost Train: 0.8949378002217022\n",
      "AdaBoost Test: 0.888806797192464\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "vect_params = {\n",
    "    'ct__text__vect__max_features' : (1000, 1500, 2000, 2500, 3000)\n",
    "}\n",
    "\n",
    "et_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('et', ExtraTreesClassifier(random_state = rs))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rsvc_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('rsvc', SVC(kernel = 'rbf'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "adbc_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('adbc', AdaBoostClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "et_grid = GridSearchCV(\n",
    "    et_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "rsvc_grid = GridSearchCV(\n",
    "    rsvc_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "adb_grid = GridSearchCV(\n",
    "    adbc_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "print(\"ET Train: {}\\nET Test: {}\\n----\".format(et_grid.score(X_train, y_train), et_grid.score(X_test, y_test)))\n",
    "print(\"RSVC Train: {}\\nRSVC Test: {}\\n----\".format(rsvc_grid.score(X_train, y_train), rsvc_grid.score(X_test, y_test)))\n",
    "print(\"AdaBoost Train: {}\\nAdaBoost Test: {}\\n----\".format(adb_grid.score(X_train, y_train), adb_grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(max_features=2500)\n",
      "CountVectorizer(max_features=1500)\n",
      "CountVectorizer(max_features=1000)\n"
     ]
    }
   ],
   "source": [
    "print(et_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(rsvc_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(adb_grid.best_estimator_['ct'].transformers[1][1]['vect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actually see more divergence in prefered number of features here. Let's do one last set of tests before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET Train: 1.0\n",
      "ET Test: 0.9157739194680458\n",
      "----\n",
      "RSVC Train: 0.9038058874245597\n",
      "RSVC Test: 0.8902844477281123\n",
      "----\n",
      "AdaBoost Train: 0.8949378002217022\n",
      "AdaBoost Test: 0.888806797192464\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "vect_params = {\n",
    "    'ct__text__vect__max_features' : (1000, 1250, 1500, 2250, 2500, 2750)\n",
    "}\n",
    "\n",
    "et_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('et', ExtraTreesClassifier(random_state = rs))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rsvc_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('rsvc', SVC(kernel = 'rbf'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "adbc_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('adbc', AdaBoostClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "et_grid = GridSearchCV(\n",
    "    et_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "rsvc_grid = GridSearchCV(\n",
    "    rsvc_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "adb_grid = GridSearchCV(\n",
    "    adbc_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "print(\"ET Train: {}\\nET Test: {}\\n----\".format(et_grid.score(X_train, y_train), et_grid.score(X_test, y_test)))\n",
    "print(\"RSVC Train: {}\\nRSVC Test: {}\\n----\".format(rsvc_grid.score(X_train, y_train), rsvc_grid.score(X_test, y_test)))\n",
    "print(\"AdaBoost Train: {}\\nAdaBoost Test: {}\\n----\".format(adb_grid.score(X_train, y_train), adb_grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(max_features=2500)\n",
      "CountVectorizer(max_features=1500)\n",
      "CountVectorizer(max_features=1000)\n"
     ]
    }
   ],
   "source": [
    "print(et_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(rsvc_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(adb_grid.best_estimator_['ct'].transformers[1][1]['vect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the same parameters here as before so let's move on to the next few parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(min_df=0.05)\n",
      "ET Train: 1.0\n",
      "ET Test: 0.9146656815663096\n",
      "----\n",
      "CountVectorizer(max_df=0.7, min_df=0)\n",
      "RSVC Train: 0.9300406453996798\n",
      "RSVC Test: 0.9009974141115626\n",
      "----\n",
      "CountVectorizer(min_df=0)\n",
      "AdaBoost Train: 0.8949378002217022\n",
      "AdaBoost Test: 0.888806797192464\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "vect_params = {\n",
    "    'ct__text__vect__max_df' : (1.0, .9, .8, .7),\n",
    "    'ct__text__vect__min_df' : (0, 0.05, 0.1, 0.2)\n",
    "}\n",
    "\n",
    "et_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('et', ExtraTreesClassifier(random_state = rs))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rsvc_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('rsvc', SVC(kernel = 'rbf'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "adbc_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', col_trans),\n",
    "        ('adbc', AdaBoostClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "et_grid = GridSearchCV(\n",
    "    et_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "rsvc_grid = GridSearchCV(\n",
    "    rsvc_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "adb_grid = GridSearchCV(\n",
    "    adbc_pipe,\n",
    "    param_grid = vect_params,\n",
    "    n_jobs = 6,\n",
    "    cv = 5\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "print(et_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(\"ET Train: {}\\nET Test: {}\\n----\".format(et_grid.score(X_train, y_train), et_grid.score(X_test, y_test)))\n",
    "print(rsvc_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(\"RSVC Train: {}\\nRSVC Test: {}\\n----\".format(rsvc_grid.score(X_train, y_train), rsvc_grid.score(X_test, y_test)))\n",
    "print(adb_grid.best_estimator_['ct'].transformers[1][1]['vect'])\n",
    "print(\"AdaBoost Train: {}\\nAdaBoost Test: {}\\n----\".format(adb_grid.score(X_train, y_train), adb_grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[1;32mc:\\Users\\vijay\\Documents\\notebooks\\dsi\\Projects\\project_3\\code\\02-Model_Building.ipynb Cell 51\u001b[0m line \u001b[0;36m4\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m rsvc_pipe \u001b[39m=\u001b[39m Pipeline(\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     [\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mct\u001b[39m\u001b[39m'\u001b[39m, col_trans),\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mrsvc\u001b[39m\u001b[39m'\u001b[39m, SVC(kernel \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrbf\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     ]\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m )\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m adbc_pipe \u001b[39m=\u001b[39m Pipeline(\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     [\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mct\u001b[39m\u001b[39m'\u001b[39m, col_trans),\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39madbc\u001b[39m\u001b[39m'\u001b[39m, AdaBoostClassifier())\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     ]\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m )\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m et_grid \u001b[39m=\u001b[39m GridSearchCV(\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     et_pipe,\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     param_grid \u001b[39m=\u001b[39m vect_params,\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     cv \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n",
      "\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m )\u001b[39m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m rsvc_grid \u001b[39m=\u001b[39m GridSearchCV(\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     rsvc_pipe,\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     param_grid \u001b[39m=\u001b[39m vect_params,\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     cv \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m )\u001b[39m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m adb_grid \u001b[39m=\u001b[39m GridSearchCV(\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     adbc_pipe,\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     param_grid \u001b[39m=\u001b[39m vect_params,\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     cv \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vijay/Documents/notebooks/dsi/Projects/project_3/code/02-Model_Building.ipynb#Y106sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m )\u001b[39m.\u001b[39mfit(X_train, y_train)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\vijay\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n",
      "\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n",
      "\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n",
      "\u001b[0;32m    870\u001b[0m     )\n",
      "\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
      "\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n",
      "\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n",
      "\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n",
      "\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\vijay\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n",
      "\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n",
      "\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\vijay\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n",
      "\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n",
      "\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n",
      "\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n",
      "\u001b[0;32m    818\u001b[0m         )\n",
      "\u001b[0;32m    819\u001b[0m     )\n",
      "\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n",
      "\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n",
      "\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n",
      "\u001b[0;32m    824\u001b[0m         X,\n",
      "\u001b[0;32m    825\u001b[0m         y,\n",
      "\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n",
      "\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39mtest,\n",
      "\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n",
      "\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n",
      "\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n",
      "\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n",
      "\u001b[0;32m    832\u001b[0m     )\n",
      "\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n",
      "\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n",
      "\u001b[0;32m    835\u001b[0m     )\n",
      "\u001b[0;32m    836\u001b[0m )\n",
      "\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n",
      "\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m    843\u001b[0m     )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\vijay\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n",
      "\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n",
      "\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n",
      "\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n",
      "\u001b[0;32m     62\u001b[0m )\n",
      "\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\vijay\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n",
      "\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretrieve()\n",
      "\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n",
      "\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\vijay\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n",
      "\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout))\n",
      "\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\vijay\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n",
      "\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n",
      "\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39mresult(timeout\u001b[39m=\u001b[39mtimeout)\n",
      "\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\vijay\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n",
      "\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n",
      "\u001b[0;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n",
      "\u001b[1;32m--> 451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n",
      "\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\vijay\\anaconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n",
      "\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n",
      "\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39macquire()\n",
      "\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# vect_params = [\n",
    "#     {\n",
    "#         'ct__text__vect__max_features' : (None, 1000, 2000, 4000, 5000),\n",
    "#         'ct__text__vect__ngram_range' : ((1,1), (1,2), (1,3)),\n",
    "#         'ct__text__vect__stop_words' : (None, 'english', stopwords.words('english')),\n",
    "#         'ct__text__vect__max_df' : (1.0, .9, .8, .7),\n",
    "#         'ct__text__vect__min_df' : (0, 0.05, 0.1, 0.2)\n",
    "#     },\n",
    "#     {\n",
    "#         'vect' : [TfidfVectorizer()],\n",
    "#         'ct__text__vect__max_features' : (None, 1000, 2000, 4000, 5000),\n",
    "#         'ct__text__vect__ngram_range' : ((1,1), (1,2), (1,3)),\n",
    "#         'ct__text__vect__stop_words' : (None, 'english', stopwords.words('english')),\n",
    "#         'ct__text__vect__max_df' : (1.0, .9, .8, .7),\n",
    "#         'ct__text__vect__min_df' : (0, 0.05, 0.1, 0.2)\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# et_pipe = Pipeline(\n",
    "#     [\n",
    "#         ('ct', col_trans),\n",
    "#         ('et', ExtraTreesClassifier(random_state = rs, n_jobs = -1))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# rsvc_pipe = Pipeline(\n",
    "#     [\n",
    "#         ('ct', col_trans),\n",
    "#         ('rsvc', SVC(kernel = 'rbf'))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# adbc_pipe = Pipeline(\n",
    "#     [\n",
    "#         ('ct', col_trans),\n",
    "#         ('adbc', AdaBoostClassifier())\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# et_grid = GridSearchCV(\n",
    "#     et_pipe,\n",
    "#     param_grid = vect_params,\n",
    "#     n_jobs = -1,\n",
    "#     cv = 5\n",
    "# ).fit(X_train, y_train)\n",
    "\n",
    "# rsvc_grid = GridSearchCV(\n",
    "#     rsvc_pipe,\n",
    "#     param_grid = vect_params,\n",
    "#     n_jobs = -1,\n",
    "#     cv = 5\n",
    "# ).fit(X_train, y_train)\n",
    "\n",
    "# adb_grid = GridSearchCV(\n",
    "#     adbc_pipe,\n",
    "#     param_grid = vect_params,\n",
    "#     n_jobs = -1,\n",
    "#     cv = 5\n",
    "# ).fit(X_train, y_train)\n",
    "\n",
    "# print(\"ET Train: {}\\nET Test: {}\\n----\".format(et_grid.score(X_train, y_train), et_grid.score(X_test, y_test)))\n",
    "# print(\"RSVC Train: {}\\nRSVC Test: {}\\n----\".format(rsvc_grid.score(X_train, y_train), rsvc_grid.score(X_test, y_test)))\n",
    "# print(\"AdaBoost Train: {}\\nAdaBoost Test: {}\\n----\".format(adb_grid.score(X_train, y_train), adb_grid.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
